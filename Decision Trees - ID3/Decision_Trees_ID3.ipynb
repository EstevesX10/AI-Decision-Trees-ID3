{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "---\n",
    "# Decision Trees - ID3 [Artificial Intelligence Project]\n",
    "---\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Problem Presentation\n",
    "***\n",
    "</div>\n",
    "    \n",
    "> ADD PROBLEM PRESENTATION"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## ID3 Algorithm \n",
    "***\n",
    "</div>\n",
    "\n",
    "A well-known decision tree approach for Machine Learning is the Iterative Dichotomiser 3 (ID3) algorithm. By choosing the best characteristic at each node to partition the data depending on information gain, it recursively constructs a tree. The goal is to make the final subsets as homogeneous as possible. By choosing features that offer the greatest reduction in entropy or uncertainty, ID3 iteratively grows the tree. The procedure keeps going until a halting requirement is satisfied, like a minimum subset size or a maximum tree depth. \n",
    "\n",
    "The ID3 Algorithm is specifically designed for building decision trees from a given dataset. It's primary objective is to construct a tree that best explains the relationship between attributes in the data and their corresponding class labels.\n",
    "\n",
    "**1. Selecting the Best Attribute:**\n",
    "- ID3 employs the concept of entropy and information gain to determine the attribute that best separates the data. Entropy measures the impurity or randomness in the dataset.\n",
    "- The algorithm calculates the entropy of each attribute and selects the one that results in the most significant information gain when used for splitting the data.\n",
    "\n",
    "**2. Creating Tree Nodes:**\n",
    "- The chosen attribute is used to split the dataset into subsets based on its distinct values.\n",
    "- For each subset, ID3 recurses to find the next best attribute to further partition the data, forming branches and new nodes accordingly.\n",
    "\n",
    "**3. Stopping Criteria:**\n",
    "- The recursion continues until one of the stopping criteria is met, such as when all instances in a branch belong to the same class or when all attributes have been used for splitting.\n",
    "\n",
    "**4. Handling Missing Values:**\n",
    "- ID3 can handle missing values to prevent overfitting. While not directly included in ID3, post-processing techniques or variations like C4.5 incorporate pruning to improve the tree's generalization."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Mathematical Concepts of ID3 Algorithm\n",
    "***\n",
    "</div>\n",
    "\n",
    "### Entropy\n",
    "\n",
    "**Entropy** is a measure of disorder or uncertainty in a set of data. It is a tool used in ID3 to measure a dataset's disorder  or impurity. By dividing the data into as homogeneous subsets as feasible, the objective is to minimze entropy.\n",
    "\n",
    "For a set $S$ with classes $\\{c_1,\\space c_2,\\space ...\\space,\\space c_n \\}$, the entropy is calculated as:\n",
    "\n",
    "$$H(S) = \\sum_{i=1}^n \\space p_i \\space log_2(p_i)$$\n",
    "\n",
    "Where $p_i$ is the proportion of instances of class $c_i$ in the set.\n",
    "\n",
    "### Information Gain\n",
    "\n",
    "Information Gain measures how well a certain quality reduces uncertainty. ID3 splits the data at each stage, choosing the property that maximizes Information Gain. It is computes using the distinction between entropy prior to and following the split.\n",
    "\n",
    "Information Gain measures the effectiveness of an Attribute $A$ in reducing uncertainty in set $S$\n",
    "\n",
    "$$IG(A,S) = H(S) - \\sum_{v \\space \\in \\space values(A)} \\frac{|S_v|}{|S|} \\cdot H(S_v))$$\n",
    "\n",
    "Where, $|S_v|$ is the size of the subset of $S$ for which attribute $A$ has value $v$.\n",
    "\n",
    "### Gain Ratio (Used more in the C4.5 Algorithm)\n",
    "\n",
    "Gain Ratio is an improvement on Information Gain that considers the inherent worth of characteristics that have a wide range of possible values. It deals with the bias of Information Gan in favor of characteristics with more pronounced values.\n",
    "\n",
    "$$ GR(A,S) = \\frac{IG(A,S)}{\\sum_{v\\space\\in\\space values(A)} \\frac{|S_v|}{|S|} \\cdot log_2(\\frac{|S_v|}{|S|})} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Problem's Resolution Approach\n",
    "***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Dependencies\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from collections import (Counter)\n",
    "\n",
    "np.random.seed(1234)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Decision Tree - ID3 [Class]\n",
    "***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "    def __init__(self, feature=None, threshold=None, information_gain=None, left=None, right=None, *, value=None):\n",
    "        # Feature and Threshold this node was divided with\n",
    "        self.feature = feature\n",
    "        self.threshold = threshold\n",
    "        self.information_gain = information_gain\n",
    "        \n",
    "        # Defining the Left and Right children\n",
    "        self.left = left\n",
    "        self.right = right\n",
    "\n",
    "        # Value of a Node -> Determines if it is a Node or not\n",
    "        self.value = value\n",
    "\n",
    "    def is_leaf(self):\n",
    "        # If a Node does not have a Value then it is not a Leaf\n",
    "        return self.value is not None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DecisionTree:\n",
    "    def __init__(self, min_samples_split=2, max_depth=100, n_features=None):\n",
    "        # Amount of Samples needed to perform a split\n",
    "        self.min_samples_split = min_samples_split\n",
    "\n",
    "        # Max depth of the decision tree\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        # Number of features (X) - Helps add some randomness to the Tree\n",
    "        self.n_features = n_features\n",
    "\n",
    "        # Defining a root - will later help to traverse the tree\n",
    "        self.root = None\n",
    "\n",
    "    def _most_common_label(self, y):\n",
    "        # Creating a Counter\n",
    "        counter = Counter(y)\n",
    "        \n",
    "        # Getting the Most Common Value\n",
    "        value = counter.most_common(1)[0][0]\n",
    "\n",
    "        # Returns most common value\n",
    "        return value\n",
    "\n",
    "    def _entropy(self, y):\n",
    "        # The Bincount method creates a numpy array with the occurences of each value.\n",
    "        # The index of the array is the number and it's value in the array corresponds to the amount of times it appears in y\n",
    "        occurences = np.bincount(y)\n",
    "\n",
    "        # Calculating every pi for every X in the previous array\n",
    "        ps = occurences / len(y)\n",
    "\n",
    "        # Returning the Entropy Value\n",
    "        return - sum(p * np.log2(p) for p in ps if p > 0)\n",
    "\n",
    "    def _split(self, X_Column, split_threshold):\n",
    "        # Splitting the Data\n",
    "        # Note: np.argwhere().flatten() returs the list of indices from the given one where it's elements obey the condition given\n",
    "        left_indices = np.argwhere(X_Column <= split_threshold).flatten()\n",
    "        right_indices = np.argwhere(X_Column > split_threshold).flatten()\n",
    "        return left_indices, right_indices\n",
    "\n",
    "    def _information_gain(self, y, X_Column, threshold):\n",
    "        # Getting the Parent Entropy\n",
    "        parent_entropy = self._entropy(y)\n",
    "\n",
    "        # Create the Children\n",
    "        left_indices, right_indices = self._split(X_Column, threshold)\n",
    "\n",
    "        # Checks if any of the lists are empty\n",
    "        if (left_indices.size == 0 or right_indices.size == 0):\n",
    "            return 0\n",
    "\n",
    "        # -> Calculate the Weighted Average Entropy of the Children\n",
    "\n",
    "        # Number of Samples in y\n",
    "        n = len(y)\n",
    "\n",
    "        # Number of samples in the Left and Right children\n",
    "        n_left, n_right = left_indices.size, right_indices.size\n",
    "\n",
    "        # Calculate the Entropy for both Samples (Left and Right)\n",
    "        entropy_left, entropy_right = self._entropy(y[left_indices]), self._entropy(y[right_indices])\n",
    "\n",
    "        # Calculate the Child Entropy\n",
    "        child_entropy = (n_left / n) * entropy_left + (n_right / n) * entropy_right\n",
    "\n",
    "        # Calculate Information Gain\n",
    "        information_gain = parent_entropy - child_entropy\n",
    "        return information_gain\n",
    "\n",
    "    def _best_split(self, X, y, feature_indices):\n",
    "        # Finds the Best existent split and threshold (Based on the Information Gain)\n",
    "\n",
    "        # Initializing the Best Parameters\n",
    "        best_gain = -1\n",
    "        split_idx, split_threshold = None, None\n",
    "\n",
    "        # Traverse all possible actions\n",
    "        for feat_idx in feature_indices:\n",
    "            X_Column = X[:, feat_idx]\n",
    "            thresholds = np.unique(X_Column)\n",
    "\n",
    "            for threshold in thresholds:\n",
    "                # Calculate the Information Gain\n",
    "                gain = self._information_gain(y, X_Column, threshold)\n",
    "\n",
    "                # Updating the Best Parameters\n",
    "                if (gain > best_gain):\n",
    "                    best_gain = gain\n",
    "                    split_idx = feat_idx\n",
    "                    split_threshold = threshold\n",
    "\n",
    "        # Returning the Best Split Criteria Found\n",
    "        return split_idx, split_threshold, best_gain\n",
    "\n",
    "    def _grow_tree(self, X, y, depth=0):\n",
    "        # Getting the number of samples, features and labels in the data given\n",
    "        n_samples, n_features = X.shape\n",
    "        n_labels = np.unique(y).size\n",
    "        \n",
    "        \"\"\"\n",
    "        # Stopping Criteria\n",
    "\n",
    "        (depth >= self.max_depth)             => Reached Maximum depth defined\n",
    "        (n_labels == 1)                       => Current Node only has 1 type of label (which means it's pure)\n",
    "        (n_samples < self.min_samples_split)  => The amount of samples is not enough to perform a split\n",
    "\n",
    "        Therefore, we must return a new node (which is going to be a leaf)\n",
    "        with the current inform\n",
    "        \"\"\"\n",
    "\n",
    "        # Checks the Stopping Criteria\n",
    "        if (depth >= self.max_depth or n_labels == 1 or n_samples < self.min_samples_split):\n",
    "            if (n_samples == 0):\n",
    "                print(y)\n",
    "\n",
    "            leaf_value = self._most_common_label(y)\n",
    "            return Node(value=leaf_value)\n",
    "        \n",
    "        # Getting the Indices of the Features\n",
    "        features_indices = np.random.choice(n_features, self.n_features, replace=False)\n",
    "\n",
    "        # Find the Best Split \n",
    "        best_feature, best_threshold, info_gain = self._best_split(X, y, features_indices)\n",
    "\n",
    "        # Create Child Nodes (Also makes a recursive call to continue to grow the tree)\n",
    "        left_indices, right_indices = self._split(X[:, best_feature], best_threshold)\n",
    "        left = self._grow_tree(X[left_indices, :], y[left_indices], depth + 1)\n",
    "        right = self._grow_tree(X[right_indices, :], y[right_indices], depth + 1)\n",
    "        \n",
    "        return Node(best_feature, best_threshold, info_gain, left, right)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        # Making sure that the amount of features does not surpass the ones available\n",
    "        if not self.n_features:\n",
    "            self.n_features = X.shape[1]\n",
    "        else:\n",
    "            self.n_features = min(X.shape[1], self.n_features)\n",
    "    \n",
    "        # Creating a Tree Recursively\n",
    "        self.root = self._grow_tree(X, y)\n",
    "            \n",
    "    def _traverse_tree(self, X, node:Node):\n",
    "        # Traverses the Tree until we reached a leaf node -> which will determine the classification label\n",
    "        if (node.is_leaf()):\n",
    "            return node.value\n",
    "\n",
    "        if (X[node.feature] <= node.threshold):\n",
    "            return self._traverse_tree(X, node.left)\n",
    "        else:\n",
    "            return self._traverse_tree(X, node.right)\n",
    "\n",
    "    def predict(self, X):\n",
    "        # Predicts the Label given an Input\n",
    "        return np.array([self._traverse_tree(x, self.root) for x in X])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Dataset [Class]\n",
    "***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset:\n",
    "    def __init__(self, file_path):\n",
    "        # Store the original dataframe\n",
    "        self.df, self.encoded_df = self._process_dataframe(file_path)\n",
    "\n",
    "        # Separates the data, target and encodes the target values returning 2 arrays and a dictionary\n",
    "        self.data, self.target, self.y_decoder = self._get_data_target()\n",
    "\n",
    "        # Variable that helps with printing the tree\n",
    "        self.cols = self.encoded_df.columns\n",
    "    \n",
    "    def _process_dataframe(self, file_path):\n",
    "        # Reading .csv file\n",
    "        df = pd.read_csv(file_path)\n",
    "\n",
    "        # Removing ID Column if existent\n",
    "        if (df.columns[0] == 'ID'):\n",
    "            df.drop(columns=['ID'], inplace=True)\n",
    "\n",
    "        # Separating Features and Labels\n",
    "        X = df[df.columns[0:-1]]\n",
    "        y = df[df.columns[-1]]\n",
    "\n",
    "        cols = X.columns\n",
    "        num_cols = X._get_numeric_data().columns\n",
    "\n",
    "        # Getting the Categorical columns within the Features\n",
    "        cat_cols = list(set(cols) - set(num_cols))\n",
    "\n",
    "        # Hot Encoding the categoricaL Features\n",
    "        new_X = pd.get_dummies(X, prefix=cat_cols, dtype='int')\n",
    "\n",
    "        # Concatenating the encoded features with the labels\n",
    "        encoded_df = pd.concat([new_X, y], axis=1)\n",
    "        \n",
    "        return df, encoded_df\n",
    "\n",
    "    def _label_encoder(self, array):\n",
    "        # Find Unique Values\n",
    "        unique_labels = sorted(np.unique(array))\n",
    "        \n",
    "        # Generate a mapping from label to integer\n",
    "        label_encoder = {label: idx for idx, label in enumerate(unique_labels)}\n",
    "        \n",
    "        # Creating a Label Decoder\n",
    "        label_decoder = {idx:label for label, idx in label_encoder.items()}\n",
    "        \n",
    "        # Map the original array to the integer labels\n",
    "        encoded_labels = np.array([label_encoder[label] for label in array])\n",
    "        \n",
    "        return encoded_labels, label_decoder\n",
    "    \n",
    "    def _get_data_target(self):\n",
    "        # Defining the Target and Label Columns\n",
    "\n",
    "        # X_Cols starts in 1 because we do not need the ID Column\n",
    "        X_Cols = self.encoded_df.columns[0:-1]\n",
    "        y_Col = self.encoded_df.columns[-1]\n",
    "    \n",
    "        # Splitting the Dataframe into features and label\n",
    "        X = self.encoded_df[X_Cols].to_numpy()\n",
    "        y, y_decoder = self._label_encoder(self.encoded_df[y_Col].squeeze().to_numpy())\n",
    "        \n",
    "        return X, y, y_decoder\n",
    "\n",
    "    def _shuffle_data(self):\n",
    "        # Note: The array[rand] actually calls the special method __getitem__\n",
    "\n",
    "        # Creating a new order\n",
    "        rand = np.arange(len(self.data))\n",
    "        np.random.shuffle(rand)\n",
    "            \n",
    "        # Rearranges the data / target arrays\n",
    "        self.data = self.data[rand]\n",
    "        self.target = self.target[rand]\n",
    "\n",
    "    def train_test_split(self, test_size=0.3):\n",
    "        # Check if the test_size if valid\n",
    "        if test_size > 1 or test_size < 0:\n",
    "            raise Exception(\"Invalid Test Size Proportion (Must be between 0 - 1)\")\n",
    "\n",
    "        # Shuffles the Data\n",
    "        self._shuffle_data()\n",
    "\n",
    "        # Defining the training size\n",
    "        train_size = int((1 - test_size) * len(self.target))\n",
    "        \n",
    "        # Splitting the data into training and testing sets\n",
    "        X_Train, X_Test = self.data[:train_size, :], self.data[train_size :, :]\n",
    "        y_Train, y_Test = self.target[:train_size], self.target[train_size :]\n",
    "        \n",
    "        # Returning the sets\n",
    "        return X_Train, X_Test, y_Train, y_Test\n",
    "\n",
    "    def _Calculate_Accuracy(self, y_Test, y_Predicted):\n",
    "        # Calculates the Accuracy given the predictions and their actual values\n",
    "        return sum(y_Test == y_Predicted) / len(y_Test)\n",
    "    \n",
    "    \"\"\" Estimate Holdout \"\"\"\n",
    "    def Estimate_Holdout(self, model=DecisionTree, test_size=0.3, *args, **kwargs):\n",
    "        # Splitting the Data\n",
    "        X_Train, X_Test, y_Train, y_Test = self.train_test_split(test_size)\n",
    "\n",
    "        # Creating a new Model\n",
    "        dt = model(*args, **kwargs)\n",
    "\n",
    "        # Train the Model\n",
    "        dt.fit(X_Train, y_Train)\n",
    "\n",
    "        # Make Predictions\n",
    "        y_Predicted = dt.predict(X_Test)\n",
    "        \n",
    "        # Calculates and Returns the Accuracy of the Model\n",
    "        return self._Calculate_Accuracy(y_Test, y_Predicted)\n",
    "    \n",
    "    def K_Fold_CV(self, total_folds=3, model=DecisionTree, *args, **kwargs):\n",
    "        # Performs a K-Fold Cross Validation\n",
    "\n",
    "        # Length of the Data\n",
    "        n = self.target.size\n",
    "\n",
    "        # Number of folds to perform\n",
    "        k = total_folds\n",
    "\n",
    "        # nfold -> size / length of each subset / fold\n",
    "        nfold = n // k\n",
    "    \n",
    "        # List to store all the calculated accuracies\n",
    "        accuracies = []\n",
    "\n",
    "        # Getting the indices for the data (will have as many as the length of the dataset)\n",
    "        indices = np.arange(n)\n",
    "        np.random.shuffle(indices)\n",
    "\n",
    "        for i in range(k):\n",
    "            # Getting the test / train indices of the current fold\n",
    "            test_indices = indices[i*nfold : (i+1)*nfold]\n",
    "            train_indices = np.concatenate([indices[: i * nfold], indices[(i + 1) * nfold:]])\n",
    "\n",
    "            # Splitting the data for each new fold\n",
    "            X_Train, y_Train = self.data[train_indices], self.target[train_indices]\n",
    "            X_Test, y_Test = self.data[test_indices], self.target[test_indices]\n",
    "\n",
    "            # Trainning and Evaluating the Model for each new fold\n",
    "            new_model = model(*args, **kwargs) \n",
    "            new_model.fit(X_Train, y_Train)\n",
    "            predictions = new_model.predict(X_Test)\n",
    "            accuracies.append(self._Calculate_Accuracy(y_Test, predictions))\n",
    "\n",
    "        # Returning the average accuracy obtained\n",
    "        return np.mean(accuracies)\n",
    "\n",
    "    def print_tree(self, dt, node=None, indent=\" \"):\n",
    "        if (dt.root is None):\n",
    "            raise Exception(\"[Unfit Model]\")\n",
    "        \n",
    "        # Checks if the Node was given\n",
    "        if not node:\n",
    "            node = dt.root\n",
    "\n",
    "        # Found a Leaf / Pure Node\n",
    "        if node.value is not None:\n",
    "            print(f\"[{self.cols[-1]}]: {self.y_decoder[node.value]}\")\n",
    "\n",
    "        # Shows the feature and threshold of the current node\n",
    "        else:\n",
    "            print(f\"'{self.cols[node.feature]}' ? [IG:{node.information_gain*100: 2.3f}%]\")\n",
    "\n",
    "            # Recursive Call to the rest of the tree\n",
    "            print(\"%sleft: \" % (indent), end=\"\")\n",
    "            self.print_tree(dt, node.left, 2*indent)\n",
    "            print(\"%sright: \" % (indent), end=\"\")\n",
    "            self.print_tree(dt, node.right, 2*indent)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Model Evaluation with the Datasets\n",
    "***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Restaurant Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(12, 11) \n",
      "\n",
      "Alt      object\n",
      "Bar      object\n",
      "Fri      object\n",
      "Hun      object\n",
      "Pat      object\n",
      "Price    object\n",
      "Rain     object\n",
      "Res      object\n",
      "Type     object\n",
      "Est      object\n",
      "Class    object\n",
      "dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Alt</th>\n",
       "      <th>Bar</th>\n",
       "      <th>Fri</th>\n",
       "      <th>Hun</th>\n",
       "      <th>Pat</th>\n",
       "      <th>Price</th>\n",
       "      <th>Rain</th>\n",
       "      <th>Res</th>\n",
       "      <th>Type</th>\n",
       "      <th>Est</th>\n",
       "      <th>Class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Some</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>30-60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Some</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Burger</td>\n",
       "      <td>0-10</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Full</td>\n",
       "      <td>$</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>Thai</td>\n",
       "      <td>10-30</td>\n",
       "      <td>Yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>No</td>\n",
       "      <td>Full</td>\n",
       "      <td>$$$</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>French</td>\n",
       "      <td>&gt;60</td>\n",
       "      <td>No</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Alt  Bar  Fri  Hun   Pat Price Rain  Res    Type    Est Class\n",
       "0  Yes   No   No  Yes  Some   $$$   No  Yes  French   0-10   Yes\n",
       "1  Yes   No   No  Yes  Full     $   No   No    Thai  30-60    No\n",
       "2   No  Yes   No   No  Some     $   No   No  Burger   0-10   Yes\n",
       "3  Yes   No  Yes  Yes  Full     $   No   No    Thai  10-30   Yes\n",
       "4  Yes   No  Yes   No  Full   $$$   No  Yes  French    >60    No"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant = Dataset(file_path='./Datasets/restaurant.csv')\n",
    "print(restaurant.df.shape, \"\\n\")\n",
    "print(restaurant.df.dtypes, \"\\n\")\n",
    "restaurant.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        0, 1, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "        1, 0, 0],\n",
       "       [0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "        0, 0, 1],\n",
       "       [1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0],\n",
       "       [1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 0, 1],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "        1, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "        0, 0, 0],\n",
       "       [0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        0, 1, 0]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant.data\n",
    "# restaurant.target\n",
    "# restaurant.features_decoders\n",
    "# restaurant.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant.data[0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# restaurant.encode_categoricaL_features()\n",
    "# restaurant.features_decoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.75"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant.Estimate_Holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6666666666666666"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "restaurant.K_Fold_CV(4, DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Type_Yes' ? [IG: 54.879%]\n",
      " left: [Class]: No\n",
      " right: 'Rain_Italian' ? [IG: 72.193%]\n",
      "  left: [Class]: Yes\n",
      "  right: [Class]: No\n"
     ]
    }
   ],
   "source": [
    "(X_Train, X_Test, y_Train, y_Test) = restaurant.train_test_split(test_size=0.3)\n",
    "dt = DecisionTree()\n",
    "dt.fit(X_Train, y_Train)\n",
    "restaurant.print_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weather Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(14, 5) \n",
      "\n",
      "Weather     object\n",
      "Temp         int64\n",
      "Humidity     int64\n",
      "Windy         bool\n",
      "Play        object\n",
      "dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Weather</th>\n",
       "      <th>Temp</th>\n",
       "      <th>Humidity</th>\n",
       "      <th>Windy</th>\n",
       "      <th>Play</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>sunny</td>\n",
       "      <td>85</td>\n",
       "      <td>85</td>\n",
       "      <td>False</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>sunny</td>\n",
       "      <td>80</td>\n",
       "      <td>90</td>\n",
       "      <td>True</td>\n",
       "      <td>no</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>overcast</td>\n",
       "      <td>83</td>\n",
       "      <td>86</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>rainy</td>\n",
       "      <td>70</td>\n",
       "      <td>96</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>rainy</td>\n",
       "      <td>68</td>\n",
       "      <td>80</td>\n",
       "      <td>False</td>\n",
       "      <td>yes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Weather  Temp  Humidity  Windy Play\n",
       "0     sunny    85        85  False   no\n",
       "1     sunny    80        90   True   no\n",
       "2  overcast    83        86  False  yes\n",
       "3     rainy    70        96  False  yes\n",
       "4     rainy    68        80  False  yes"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = Dataset(file_path='./Datasets/weather.csv')\n",
    "print(weather.df.shape, \"\\n\")\n",
    "print(weather.df.dtypes, \"\\n\")\n",
    "weather.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# weather.data\n",
    "# weather.target\n",
    "# weather.y_decoder\n",
    "# weather.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.Estimate_Holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather.K_Fold_CV(10, DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'Weather_sunny' ? [IG: 55.773%]\n",
      " left: [Play]: yes\n",
      " right: 'Humidity' ? [IG: 81.128%]\n",
      "  left: [Play]: yes\n",
      "  right: [Play]: no\n"
     ]
    }
   ],
   "source": [
    "(X_Train, X_Test, y_Train, y_Test) = weather.train_test_split(test_size=0.3)\n",
    "dt = DecisionTree()\n",
    "dt.fit(X_Train, y_Train)\n",
    "weather.print_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Iris Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(150, 5) \n",
      "\n",
      "sepallength    float64\n",
      "sepalwidth     float64\n",
      "petallength    float64\n",
      "petalwidth     float64\n",
      "class           object\n",
      "dtype: object \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepallength</th>\n",
       "      <th>sepalwidth</th>\n",
       "      <th>petallength</th>\n",
       "      <th>petalwidth</th>\n",
       "      <th>class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>5.1</td>\n",
       "      <td>3.5</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>4.9</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4.7</td>\n",
       "      <td>3.2</td>\n",
       "      <td>1.3</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.6</td>\n",
       "      <td>3.1</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.6</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>Iris-setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sepallength  sepalwidth  petallength  petalwidth        class\n",
       "0          5.1         3.5          1.4         0.2  Iris-setosa\n",
       "1          4.9         3.0          1.4         0.2  Iris-setosa\n",
       "2          4.7         3.2          1.3         0.2  Iris-setosa\n",
       "3          4.6         3.1          1.5         0.2  Iris-setosa\n",
       "4          5.0         3.6          1.4         0.2  Iris-setosa"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris = Dataset(file_path='./Datasets/iris.csv')\n",
    "print(iris.df.shape, \"\\n\")\n",
    "print(iris.df.dtypes, \"\\n\")\n",
    "iris.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# iris.data\n",
    "# iris.target\n",
    "# iris.y_decoder\n",
    "# iris.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.Estimate_Holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9266666666666667"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.K_Fold_CV(10, DecisionTree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "'petalwidth' ? [IG: 94.425%]\n",
      " left: [class]: Iris-setosa\n",
      " right: 'petalwidth' ? [IG: 79.371%]\n",
      "  left: 'sepallength' ? [IG: 17.557%]\n",
      "    left: [class]: Iris-versicolor\n",
      "    right: [class]: Iris-virginica\n",
      "  right: 'petallength' ? [IG: 14.743%]\n",
      "    left: 'sepalwidth' ? [IG: 100.000%]\n",
      "        left: [class]: Iris-virginica\n",
      "        right: [class]: Iris-versicolor\n",
      "    right: [class]: Iris-virginica\n"
     ]
    }
   ],
   "source": [
    "(X_Train, X_Test, y_Train, y_Test) = iris.train_test_split(test_size=0.3)\n",
    "dt = DecisionTree()\n",
    "dt.fit(X_Train, y_Train)\n",
    "iris.print_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect-Four Dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(67557, 43) \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>X1</th>\n",
       "      <th>X2</th>\n",
       "      <th>X3</th>\n",
       "      <th>X4</th>\n",
       "      <th>X5</th>\n",
       "      <th>X6</th>\n",
       "      <th>X7</th>\n",
       "      <th>X8</th>\n",
       "      <th>X9</th>\n",
       "      <th>X10</th>\n",
       "      <th>...</th>\n",
       "      <th>X34</th>\n",
       "      <th>X35</th>\n",
       "      <th>X36</th>\n",
       "      <th>X37</th>\n",
       "      <th>X38</th>\n",
       "      <th>X39</th>\n",
       "      <th>X40</th>\n",
       "      <th>X41</th>\n",
       "      <th>X42</th>\n",
       "      <th>WIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>o</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>...</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>b</td>\n",
       "      <td>win</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 43 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  X1 X2 X3 X4 X5 X6 X7 X8 X9 X10  ... X34 X35 X36 X37 X38 X39 X40 X41 X42  WIN\n",
       "0  b  b  b  b  b  b  b  b  b   b  ...   b   b   b   b   b   b   b   b   b  win\n",
       "1  b  b  b  b  b  b  b  b  b   b  ...   b   b   b   b   b   b   b   b   b  win\n",
       "2  b  b  b  b  b  b  o  b  b   b  ...   b   b   b   b   b   b   b   b   b  win\n",
       "3  b  b  b  b  b  b  b  b  b   b  ...   b   b   b   b   b   b   b   b   b  win\n",
       "4  o  b  b  b  b  b  b  b  b   b  ...   b   b   b   b   b   b   b   b   b  win\n",
       "\n",
       "[5 rows x 43 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C4 = Dataset(file_path='./Datasets/connect4.csv')\n",
    "print(C4.df.shape, \"\\n\")\n",
    "# print(C4.df.dtypes, \"\\n\")\n",
    "C4.df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# C4.data\n",
    "# C4.target\n",
    "# C4.features_decoders\n",
    "# C4.cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# C4.Estimate_Holdout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# (X_Train, X_Test, y_Train, y_Test) = C4.train_test_split(test_size=0.3)\n",
    "# dt = DecisionTree()\n",
    "# dt.fit(X_Train, y_Train)\n",
    "# C4.print_tree(dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Just for Guidance [REMOVE LATER]\n",
    "***\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import (datasets)\n",
    "from sklearn.model_selection import (train_test_split)\n",
    "from sklearn.metrics import (accuracy_score)\n",
    "from sklearn.tree import (DecisionTreeClassifier)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(y_test, y_pred):\n",
    "    return sum(y_test == y_pred) / len(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6666666666666666\n"
     ]
    }
   ],
   "source": [
    "res =  Dataset(file_path='./Datasets/restaurant.csv')\n",
    "\n",
    "X = res.data\n",
    "y = res.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "res =  Dataset(file_path='./Datasets/weather.csv')\n",
    "\n",
    "X = res.data\n",
    "y = res.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9736842105263158\n"
     ]
    }
   ],
   "source": [
    "res =  Dataset(file_path='./Datasets/iris.csv')\n",
    "\n",
    "X = res.data\n",
    "y = res.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7588513913558319\n"
     ]
    }
   ],
   "source": [
    "res =  Dataset(file_path='./Datasets/connect4.csv')\n",
    "\n",
    "X = res.data\n",
    "y = res.target\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(X, y)\n",
    "\n",
    "dt = DecisionTreeClassifier()\n",
    "dt.fit(x_train, y_train)\n",
    "\n",
    "y_pred = dt.predict(x_test)\n",
    "print(\"Accuracy:\", accuracy(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Advantages and Disadvantages of ID3\n",
    "***\n",
    "</div>\n",
    "\n",
    "### **Advantages**\n",
    "\n",
    "- **Interpretability**: Decision Trees generated by ID3 are **easily interpretable**, making them usefull for explaining decisions to non-technical stakeholders\n",
    "- **Handles Categorical Data**: ID3 can effectively **handle categorical attributes** without explicit data preprocessing steps\n",
    "- **Not Computationally Expensive**: The Algorithm is relatively straightforward and **computationally less expensive** compared to some complex models\n",
    "\n",
    "### **Disadvantages**\n",
    "\n",
    "- **Overfitting**: ID3 tends to create complex trees that may **overfit over the training data**, impacting its performance upon new unseen information\n",
    "- **Sensitive to Noise**: Noise or outliers in the data can lead to the **creation of non-optimal or incorrect splits**\n",
    "- **Exclusive to Binary Trees**: ID3 only constructs **binary trees** which **limits** its ability to **express more complex relationships** within the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Conclusion\n",
    "***\n",
    "</div>\n",
    "\n",
    "The **ID3 Algorithm** laid the groundwork for **decision tree learning**, providing a robust framework for understanding **attribute selection** and **recursive partitioning**. Despite its limitations, ID3's simplicity and interpretability have paved the way for more sophisticated algorithms that address its drawbacks while retaining its essence.\n",
    "\n",
    "As **Machine Learning** continues to evolve, the ID3 Algorithm remains a **crucial piece** in the mosaic of tree-based methods, serving as a stepping stone for developing **more advanced and accurate models** in the quest for **efficient data analysis and pattern recognition**.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "<div align=\"center\">\n",
    "\n",
    "***\n",
    "## Bibliographic References\n",
    "***\n",
    "</div>\n",
    "\n",
    "1. Geeks For Geeks (2023). *Decision Tree Algorithms*. Available [here](https://www.geeksforgeeks.org/decision-tree-algorithms/#id3-iterative-dichotomiser-3)\n",
    "2. Geeks For Geeks (2024). *Iteratice Dichotomiser 3 (ID3) Algorithm From Scratch*. Available [here](https://www.geeksforgeeks.org/iterative-dichotomiser-3-id3-algorithm-from-scratch/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "## Video Presentation (YouTube Video)\n",
    "\n",
    "Moreover, you can find the **Video** for our **Project's Presentation [here](https://youtu.be/dQw4w9WgXcQ?si=NfwpqDkOwLRY6tRQ)**\n",
    "___\n",
    "## Final Considerations\n",
    "\n",
    "$\\quad$ If there is any difficulty on downloading or executing this project, please contact us via:\n",
    "\n",
    "- **Email**:\n",
    "    - [GonÃ§alo Esteves](https://github.com/EstevesX10) &#8594; `up202203947@up.pt`\n",
    "    - [Maximino Canhola](https://github.com/MaximinoCanhola) &#8594; `up201909805@up.pt`\n",
    "    - [Nuno Gomes](https://github.com/NightF0x26) &#8594; `up202206195@up.pt`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
